# 操作系统

## 进程

##### 1、进程的**概念**：

是静态可执行文件加载到内存中，cpu执行内存中的指令。资源调度的基本单位

##### 2、进程的**管理**：

os维护进程表，表项PCB，PCB包含进程描述信息（进程/用户标识符），控制信息（**状态**、优先级）、资源分配清单（内存、文件列表、IO设备）、CPU信息；通过链表组织起来。

##### 3、进程的**状态**：

就绪、运行、阻塞、创建、结束、就绪挂起、阻塞挂起

##### 4、和**线程对比**：

虚拟地址切换较慢，线程切换不涉及，进程切换导致TLB（快表失效），命中率降低，线程不会导致失效

##### 5、进程的**种类**：

- **守护进程**：web服务器
  - 程序在后台运行，`fork()`一个新的子进程
  - 调用`setsid()`创建一个新的对话期。新的子进程成为新的会话组长和进程组长，并摆脱父进程的影响。
  - 禁止进程重新打开控制终端。通过`fork()`再次创建新的子进程，使调用的fork进程退出
  - 关闭文件描述符
  - 将当前目录更新位根目录
  - 使用unmask将屏蔽字清零
  - 处理SIGCHLD信号。比如将信号SIGCHLD设为SIG_IGN，这样子进程结束不会产生僵尸进程
- **僵尸进程**
  - 子进程退出后，父进程还在运行，子进程就成了僵尸进程。目的是为了维护子进程信息，方便主进程通过wait或者waitpid获取。但是僵尸进程会占用内核资源。、所以通过执行非阻塞可以提高程序效率，或者通过设置SIG_IGN（忽略信号）表示内核对子进程结束不关心，由**内核回收**，主进程就不用管了，正常结束就行了。

##### 6、多进程问题：

代码段，堆栈端，数据段。代码段多个进程共享

父子进程除了pid都一样

父子进程共享全部数据，但是子进程写数据会采用写时复制，不是对同一块数据操作

调用execv()可以加载新的代码段，与父进程独立开

##### 7、进程调度：

- FCFS：非抢占式，利长作业
- 最短优先：非抢占式。利于短作业，长作业会“饿”’
- 最短剩余时间：
- 时间片：
- 优先级调度：
- 多级队列：时间片+优先级
- 最短进程优先：

##### 8、进程通信

- 同一主机

  - 管道：

    - 无名pipe

      半双工、先入先出、无格式、只存在内存、读数据是一次性操作、没有名字之存在于亲缘进程间，存在阻塞。pipe函数、读端和写端、

    - 有名fifo

      有名字非亲缘进程也可以访问、有具体文件、mkfifo fifo创建

  - 信号：

    - 软中断
    - 异步通信
    - 用户和内核空间进程交互
    - 硬件异常或者软件异常，调用系统函数，按下终端键（crtl+C）、kill命令
    - 编号，名称，事件，执行动作

  - 消息队列：

  - 共享存储映射：

    - 最快，不需要数据拷贝，直接读写内存
    - 使得磁盘文件和存储空间的缓冲区映射
    - 不适用read和write，使用指针完成IO操作。
    - mmap、munmap函数
    - 零拷贝

- 不同主机

  - socket

## 线程

轻量级进程，也有PCB、创建线程使用的底层函数和进程一样都是clone

最小执行单位

clone复制对方地址空间就是进程，共享对方地址空间就是线程

linux内核不区分进程和线程，只在用户面区分，所以线程函数都是库函数，不是系统调用



##### 三种线程：

- 用户线程：用户空间的线程
  - 不由OS调度，一旦阻塞，此进程下的用户线程都无法运行
  - 用户线程一旦执行，不会被别的用户线程打断。因为OS不会参与用户线程调度
- 内核线程：
  - os调度
  - 内核线程阻塞，不会影响别的线程
  - 占用内核资源、开销较大
- 轻量级LWP
  - 内核支持的用户线程，向普通进程一样调度，类似进程中的执行线程
  - 实际的用户线程是运行再LWP之上的

##### 资源：

线程共享的资源：文件描述符表、每种信号处理方式、工作目录、用户组iD和组id

非共享资源：线程id、处理线程和栈指针、栈空间、erro变量、信号屏蔽字、调度优先级

##### 优缺点

优点：提高并发性、开销小、数据通信，共享数据方便

缺点：库函数，不稳定、调试困难、对信号支持不好

创建快、切换快、终止快、通信快

多线程的好处：开销小、IO密集型、并发



## 协程







## 互斥同步

##### 互斥锁

两种状态：枷锁和解锁

##### 死锁：

- 必要条件：互斥、占有和等待、不可抢占、环路
- 处理：
  - 鸵鸟：当死锁发生概率低并且影响小
  - 检测和恢复：
    - 检测算法：有向图是否有环
    - 恢复：抢占、回滚、杀死进程
  - 预防
    - 破坏互斥条件、破坏占有等待、破坏不可抢占、破坏环路等待
  - 避免：
    - 安全状态、银行家算法



##### 读写锁：	

允许多读，不允许多写。

##### 条件变量：

用来等待的而不是上锁的。

- mutex在消费者之间也会竞争，使用条件变量，只有在生产者完成生产消费者才会竞争

信号量：控制对公共资源的访问、PV原语，P是-1V是+；

##### 管程



## 存储系统

##### 层次结构：

- 寄存器：最快，半个cpu时钟周期完成读写。
- cache：SRAM（静态随机存储器）、分三层
- 内存：DRAM（动态随机存储器），更便宜，电容定时刷新，速度在200左右时钟周期
- 外存：固体硬盘>机械硬盘（物理读取）

##### 页面置换算法：

- 最佳页面置换OPT：无法实现，作为衡量标准
- 先进先出：
- 最近最久未使用LRU
- 时钟页面置换：环形链表，遍历时为1则值为0，为0则置换出去
- 最不常用：需要统计页面访问次数，额外开销

##### 分段：

​	将表分段，一个段构成一个独立的地址空间，长度可以不同，并且可以动态增长

​	分页用于实现虚拟空间，获得更大的地址空间；分段是为了程序的独立有利于共分享和保护

- 纯分段：有利于几个进程间**共享**数据、每个段独立增长，不会影响其他段（**保护**）
- 分段+分页：先分段，段上分页：既共享个保护又又分页的虚拟内存功能
- 比较
  - 分页对程序员透明，分段需要程序员显示操作
  - 维度：分页一维、分段二维
  - 大小：分页可改、分段不行

##### 虚拟内存（分页）：

​	应用程序以为的连续内存，实际上是多个物理页

​	通过硬件异常、硬件地址翻译、主存、磁盘和内核软件共同完成

​	看起来足够大、独立所以可以简化程序连接装在和内存分配过程、隔离对物理内存的访问权限更安全

- 加速分页
  - TLB加速分页：TLB将虚拟地址和物理地址直接映射。硬件进行匹配，如果匹配到就不用访问页表，没匹配到就查询页表并更新到TLB
  - 软件TLB管理
- 多级页表、倒排页表
- 高速缓存：
- 内存保护：通过页表中页表条目的一些标志位实现对虚拟页的访问控制权限
- 内存管理：

## 文件系统

##### 磁盘调度算法：

- FCFS
- SSTF：寻道时间最短，造成饥饿
- SCAN：类似电梯

##### 中断处理：

## IO复用

IO操作就是针对内存而言，在运行代码的过程中，内存对文件的读写操作。可以分为网络IO和磁盘IO。

IO操作一般分为两步：1、等待数据准备好。2、从内核向进程复制数据。例如：等待数据从网络中到达后复制到内核的缓冲区；然后将数据从缓冲区输入到应用进程。

#### 五种IO模型

1. 阻塞式IO：进程或者线程等待某个条件，如果条件不满足就一直等下去。条件满足就进行下一步操作。应用进程会阻塞在系统调用recvfrom。

   优点：设备文件不可操作时，可以进入休眠状态，将cpu资源让出去；当可以操作时就唤醒进程；

   缺点：耗费时间，适合并发低，时效性低的情况

   ![image-20230821135615392](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20230821135615392.png)

2. 非阻塞式IO：应用进程和内核交互，数据未准备好的时候，不会阻塞等待唤醒，而是不停的轮询recvfrom，如果数据准备好，就复制数据到进程空间。

   缺点：轮询操作是系统调用，不停轮询会耗费大量的cpu时间。![image-20230821140357089](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20230821140357089.png)

3. IO复用：通过调用select或者poll，阻塞在着三个系统调用中的一个，而不是阻塞在recvform系统调用上。当select监视的文件描述符fd返回可读时，再调用recvfrom将数据读到进程空间。

   - 如果所有监听的fd都为准备好，就阻塞
   - 任意一个fd准备好，select调用返回
   - 用户进程通过recvfrom进行数据拷贝

   优点：不会一直轮询，释放了cpu资源；可以同时监听多个描述符。![image-20230821141342217](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20230821141342217.png)

4. 信号驱动IO：开启套接字信号驱动功能，通过sigaction系统调用安装一个信号处理函数，该函数立即返回，不阻塞；数据报准备好后，内核为该进程产生一个sigio信号交给进程；然后信号处理函数调用recvfrom读取数据。

   优点：等待数据等待期间不会阻塞，进程可以继续执行等待信号到来；![image-20230821145210107](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20230821145210107.png)

5. 异步IO：用户进程通知内核启动某个操作，并由内核完成后通知用户进程。也叫事件驱动IO。信号驱动IO是内核通知可以执行IO操作了，异步IO是内核通知IO操作何时完成。![image-20230821150449586](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20230821150449586.png)

6. 关**于epoll是异步还是同步：原理上是同步，但是在实际使用中，实现了和异步一样的效率，和异步是一样的。同步和异步最大的区别就在于这两个阶段是否有一个或者全部阻塞。因为虽然使用epoll的程序也会阻塞在epoll处，但是在返回可读条件后，进程调用read即recvfrom的时候不会阻塞在复制数据处，因为mmap技术，用户空间和内核空间实现了共享，所以调用read后可以直接返回不会阻塞。**  但是，epoll是事件驱动机制的，从这个角度上来说，epoll也是异步的。

   

#### poll/epoll/select

select:两次遍历+两次拷贝

- 将已连接的socket放在一个文件描述符集合中，调用select函数将文件描述符**拷贝**到内核，内核检查是否有网络事件发生
- **遍历**，有事件就将改socket置为读/写，然后再**拷贝**回用户空间
- 用户再**遍历**处理刚刚标记的socket

poll：动态数组，以链表的形式来组织，相比于select，没有文件描述符个数的限制，当然也会收到系统文件描述符的限制

epoll：红黑树

- 内核里面使用红黑树跟踪进程待检测的文件描述符
- 调用epoll_ctl()，将需要监控的socket加入到内核的红黑树中，每次只需要传入一个待检测的sockey，减少了内核和用户空间大量的拷贝和内存分配
- 使用事件驱动机制，内核维护了一个链表来记录就绪事件。当某个socket有时间发生时，通过回调函数，内核会将其加入到这个就绪事件列表中
- 当用户调用epoll_wait的时候，只会返回有事件发生的文件描述符的个数，不需要向另外两个函数轮询
- 两种触发模式
  - ET：当被监控的Scoket描述符上有事件发生，服务器只从epoll_waitr苏醒一次，因此程序需要一次将数据读完，读到EGAIN。只触发一次
  - LT：当被监控的Scoket描述符上有事件发生，服务器不断从epoll_waitr苏醒，直到缓冲区数据读完。
  - ET模式在很大程度上减少了epoll事件被重复触发的次数，因此**效率要比LT模式高**。epoll工作在ET模式的时候，必须使用**非阻塞套接口**，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。
  - 使用ET的例子:nginx
    使用LT的例子:redis

select和epoll区别：

- 时间复杂度：select和poll采用轮询方式检查就绪事件，复杂度**O（n）**epoll采用回调方式检测就绪时间，只返回有时间发生的文件描述符的个数，复杂度**O(1)**
- 工作模式：select工作在**LT模式，epoll可以工作在ET模式**
- 操作系统：epoll是linux特有的，select是os都有的
- 描述符数量：select单个进程监视的文件描述符有限，64位是2048个；epoll没有最大并发连接的限制，远大于2048
- 消息传递：select需要将消息传递到用户空间，需要拷贝；epoll通过共享内存实现。

# 网络

## 应用层



## 传输层



## 网络层（数据平面）：



## 网络层（控制平面）：

##### **概念：**

控制源主机到目的主机之间如何沿着端到端路径转发数据报、控制网络层组件和服务器的配置管理

##### **两类**：

- 每路由控制
- 集中控制（SDN控制）
  - SDN控制应用程序
  - SDN控制器

##### **路由选择算法：**

- 链路状态LS：OSPF
- 距离向量DV：BGP

##### **协议**

- ICMP：互联网控制报文协议
- SNMP：简单网络控制协议（应用层UDP）

## 链路层

##### 服务：

成帧、链路访问控制MAC、差错检测纠正、可靠交付

网络适配器

##### 差错检测：

- 奇偶校验：检测不能纠正
- 循环冗余校验
- 检验和（一般运输层使用）

##### 多路访问协议

- 信道划分：时分多路复用、频分多路复用、码分多址（每个节点不同的编码。可以同时发送数据进行编码）
- 随机接入：ALOHA（时隙<p重传>、非时隙<>）、载波侦听CSMA（以太网,CSAM（说话之前先听）和CSMA/CD（如果同时说话就停止说话））
- 轮流协议：轮询、令牌

##### 交换局域网

- 链路层寻址和ARP

#### **数据中心：**



## **web页面请求历程**



1、准备DHCP、UDP、IP、以太网

1. 电脑发送DHCP请求报文
   1. 生成DHCP请求报文，端口号67 （目的）和68。该UDP报文段广播目的（255.255.255.255）和源（0.0.0.0）的IP数据报
   2. DHCP请求报文放入**以太网帧**中，目的MAC地址（全F），广播到DHCP服务器。源MAC就是本机MAC地址
   3. 该帧经过交换机广播出去
   4. 和交换机连接的路由器接受到广播帧，该帧中包含了DHCP报文，从以太网帧中抽出Ip数据包，解析ip数据报的载荷udp报文段，DHCP请求报文从UDP报文中抽出来。DHCP服务器就有了DHCP报文
2. DHCP服务器响应
   1. DHCP服务器使用CIDP分配一个IP地址。生成包含这个IP地址、DNS服务器的IP地址、默认网关的路由器IP、子网掩码的DHCP ACK应答报文。该DHCP报文放入UDP报文中，IP数据包中、以太帧中，目的MAC即电脑的MAC地址
   2. DHCP应答报文经过路由器发送给交换机，然后发送给便携机
   3. 便携机收到DHCP ACK，然后一步步解析获取出其中分配给本机的IP地址、DNS服务器地址，并且在IP转发表中安装默认网关的地址。

2、准备DNS、ARP

当输入URL后，为了交互必须知道URL的ip地址，所以必须经过DNS查询

1. 生成一个DNS查询报文，将URL放入DNS的报文段中，然后放在53号目的端口的UDP报文段中，该UDP报文段放入具有DNS服务器的目的IP的IP报文中。
2. 将该ip数据报文放入以太网帧中。经过第一步已经知道网关ip地址，但是不知道MAC地址，于是电脑使用ARP协议
3. 生成一个ARP查询报文，广播该ARP报文（全F）的以太网帧，发送
4. 网关路由器收到ARP查询报文的帧，准备一个ARP应答报文，将IP地址和MAC地址打包发送回去
5. 电脑接收ARP应答报文，解析出网关MAC地址。然后就可以将DNS查询报文经过网关路由器发送出去了。

3、准备域内路由选择到DNS服务器

1. DNS查询报文经过域内协议（OSPF、RIP）生成的转发表转发出去，经过BGP域间转发
2. DNS服务器收到DNS查询报文后，在DNS数据库中找到对应的IP地址。经过迭代和轮询的方式访问各级DNS服务器。将映射的IP地址打包成DNS回答报文传回去。
3. 电脑收到谷歌服务器的IP地址。

4、web客户和服务器交互：TCP和HTTP

1. 电脑有了目的IP地址，可以生成TCP套接字


# 设计模式

### 单例

一个类一个实例，并提供一个全局访问点;避免全局使用的类，频繁创建和销毁，耗费系统资源。

##### 实现：

- 构造函数私有化
- 静态方法访问点
- 私有静态变量
- 加锁互斥判唯一

##### 6种实现方式(重点1-5)

###### 1、懒汉线程不安全

优点：延迟了实例化，不调用就不会实例，节省资源

缺点：线程不安全。多线程同时进入判断中

```c++
class Single{
    private:
    	Single(){};
    	static Single  instance;
    public:
    	static Single getIns(){
            if(instance == nullptr){
                instance = new Single();
            }
            return instance;
    }
}
```

###### 2、懒汉安全

优点：线程安全，在函数上加了锁

缺点：即使已经实例化了，进入函数还是都要加锁，进入该方法会堵塞，等待时间长

```c++
class Single{
    private:
        Single(){};
    	static Single ins;
    	static mutex mtx;
    public:
    	static Single getIns(){
            lock_guard<mutex> lock(mtx);
            if(instance == nullptr){
                instance = new Single();
            }
            return instance;
    	}
}
```

###### 3、双重锁检查

线程安全，并且不会因为获取锁阻塞。

```c++
class Single{
    private:
    	Single(){}
    	static Single ins;
        static mutex mtx;
    public:
    	static Single getIns(){
            if(ins == nullptr){
                lock_groud<mutex> lock(mtx);
                if(ins == nullptr){
                    ins = new Single();
                }
            }
            return ins;
        }
}
```

当使用了锁来保护对 `instance` 的访问时，在单线程的情况下，不需要将其声明为 `volatile`。只有在没有使用锁或其他同步机制的情况下，当存在多个线程同时访问 `instance` 时，才需要将其声明为 `volatile` 来确保内存的可见性和一致性。

###### 4、饿汉式线程安全

直接实例化好，所以天然没有线程安全问题；

不延迟实例化会浪费系统资源。

```c++
class Single{
    private:
    	Single(){}
    	static Single ins = new Single();
    public:
    	Single getIns(){
            return ins;
        }
}
```

###### 5、静态内部类实现(线程安全)

当single被加载的时候，静态内部类并没有被记载进内存。当调用getIns的时候彩才会被加载进内存，并初始化实例。

```c++
class Single{
    private:
    	Single(){}
    	static class SingleHold{
            private static final Single ins = new Single();
        }
    public:
    	static Single getIns(){
            return SingleHold.ins;
        }
}
```

###### 6、枚举类实现(java C++感觉不太行)

默认枚举实例的创建就是线程安全的，且在任何情况下都是单例。

优点：

写法简单，线程安全，天然防⽌反射和反序列化调⽤。

```java
public enum Singleton {
 INSTANCE;
 //添加⾃⼰需要的操作
 public void doSomeThing() {}
}
```

##### 应用场景

频繁创建和销毁的对象、线程池等控制资源，方便资源之间的通信

1. 日志应用
2. 配置对象的读取
3. 数据库连接池
4. 多线程池
5. 网站计数器

### 工厂模式

创建型设计模式、在创建对象时，不会对客户端暴露对象的创建逻辑，⽽是通过使⽤共同的接⼜来创建对象。其⽤来封装和管理类的创建，本质是对获取对象过程的抽象。
⼯⼚模式分成**简单⼯⼚⽅法**和**抽象⼯⼚**

**优点：**
				**解耦**：将对象的创建和使⽤进⾏分离
				**可复⽤**：对于创建过程⽐较复杂且在很多地⽅都使⽤到的对象，通过⼯⼚模式可以提⾼对象创建的代码的复⽤性。
				**降低成本**：由于复杂对象通过⼯⼚进⾏统⼀管理，所以只需要修改⼯⼚内部的对象创建过程即可维护对象，从⽽达到降低成本的⽬的。

###### 简单工厂模式

在简单⼯⼚模式中，可以根据实际的参数不同返回不同的实例。同时在简单⼯⼚模式中会定义⼀个类负责创建其他类的实例，被创建的实例也通常具有共同的⽗类。

虽然实现了对象的创建和使⽤的分离，但是不够灵活，⼯⼚类集合了所有产品的创建逻辑，职责过重，同时新增⼀个产品就需要在原⼯⼚类内部添加⼀个分⽀，违反了开闭原则。并且若是有多个判断条件共同决定创建对象，则后期修改会越来越复杂。

###### 抽象工厂模式：**多加了一层抽象类**

⼯⼚⽅法模式中，将简单⼯⼚中的⼯⼚类变为⼀个抽象接⼜。负责给出不同⼯⼚应该实现的⽅法，⾃⾝不再负责创建各种产品，⽽是将具体的创建操作交给实现该接⼜的⼦⼯⼚类来做。

通过多态的形式解决了简单⼯⼚模式过多的分⽀问题。虽然在新增产品时不仅要新增⼀个产品类还要实现与之对应的⼦⼯⼚，但是相较于简单⼯⼚模式更符合开闭原则。

### 观察者模式

⾏为型模式、⼀对多的依赖关系、让多个观察者对象同时监听某⼀个主题对象。这个主题对象在状态变化时，会通知所有的观察者对象，使他们能够⾃动更新自己。

**优点：**解除耦合，让耦合的双⽅都依赖于抽象，从⽽使得各⾃的变换都不会影响另⼀边的变换

**缺点：**调试复杂，⽽且在Java中消息的通知⼀般是顺序执⾏，那么⼀个观察者卡顿，会影响整体的执⾏效率，在这种情况下，⼀般会采⽤异步实现。 

### 装饰器模式

装饰模式把每个要装饰的功能放在单独的类中，并让这个类包装它所要装饰的对象。因此，当需要执⾏特殊⾏为时，客户代码就可以在运⾏时根据需要有选择地、按顺序地使⽤装饰功能包装对象了。

### 代理模式

为其他对象提供⼀种代理以控制对这个对象的访问。

###### 应用

- 远程代理：⼀个对象在不同的地址空间提供局部代表。这样可以隐藏⼀个对象存在于不同地址空间的事实。
- 虚拟代理：**根据需要创建开销很⼤的对象**。通过它来存放实例化需要很长时间的真实对象，这样就可以达到性能的最优化。⽐如说你打开⼀个很⼤的HTML⽹页时，⾥⾯可能有很多的⽂字和图⽚，但你还是可以很快打开它，此时你所看到的是所有的⽂字，但图⽚却是⼀张⼀张地下载后才能看到。那些未打开的图⽚框，就是通过虚拟代理来替代了真实的图⽚，此时代理存储了真实图⽚的路径和尺⼨。
- 安全代理：⽤来控制真实对象访问时的权限。
- 智能指引：**是指当调⽤真实的对象时，代理处理另外⼀些事。**如计算真实对象的引⽤次数，这样当该对象没有引⽤时，可以⾃动释放它；或当第⼀次引⽤⼀个持久对象时，将它装⼊内存；或在访问⼀个实际对象前，检查是否已经锁定它，以确保其他对象不能改变它。它们都是通过代理在访问⼀个对象时附加⼀些内务处理。 



# 计算机系统

##### 字符编码

固定长度编码

可变长度编码（UTF-8）

##### 冯诺依曼模型

五大部件：CPU（控制单元、寄存器、逻辑运算单元）、内存、总线（数据、控制、内存）、输入、输出

<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20230823152137978.png" alt="image-20230823152137978" style="zoom:50%;" />

###### CPU

32位CPU一次可以处理4字节

通用寄存器：放运算数据、程序计数器（PC计数器、存放下一条要执行的指令）、指令寄存器（存放PC执行的指令，PC去之后放入指令寄存器中）

###### 总线：CPU和其他部件的通信

地址总线：CPU要操作的内存地址

数据总线：读写内存数据

控制总线：收发信号、中断、设备复位

###### **程序执行过程**

流水线：4级

取指、译指、执行、数据回写

取指：cpu控制单元通过地址总线发送PC中的地址，内存中找到待执行指令、然后传输到指令寄存器、更新PC

译指：分析指令，计算型交给逻辑单元、存储型交给控制单元

执行：根据指令执行

回写：会写到寄存器或者内存

##### 编译系统

预处理-----》编译-----》汇编------》链接

gcc -E------》gcc -S----》gcc -c---》

预处理：.c--->gcc -E---->.i   展开宏、头文件、替换条件编译、删除注释

编译：.i----->gcc -S----->.s 检查语法规范。时间最久，系统资源最多

汇编：.s----->gcc -c----->.o汇编指令翻译成机器指令

链接：a.out    数据段合并，地址回填

静态库在编译时候链接，嵌入到可执行程序中，动态库在运行时连接。

##### [运行一个hello程序](https://zhuanlan.zhihu.com/p/513307151)

**简单版本**

1、输入“./hello”，shell程序会将字符读入寄存器，处理器将hello字符传放入内存中

2、按下空格键，完成命令的输入，然后执行一系列的指令来加载可执行文件，将hello中的数据和代码从磁盘复制到内存。数据就是hello。复制过程利用DMA技术，不经处理器从磁盘直达内存。

3、处理器开始执行main函数中的代码。

4、cpu将hello从内存复制到寄存器文件，然后从寄存器复制到显示设备、显示

**复杂版本：**

第一步、进程

1. 在 Shell 中输入 hello 程序的路径
2. Shell 判断用户输入的是否为内置命令，如果不是，就认为它是一个可执行目标文件
3. Shell 构造 argv 和 envp
4. Shell 使用 fork() 创建子进程，调用 execve() 函数在新创建的子进程的上下文中加载并运行 hello 程序。将 hello 中的 .text 节、.data 节、.bss 节等内容加载到当前进程的虚拟地址空间
5. execve() 函数调用加载器，跳转到程序的入口点，开始执行 _start 函数，我们的 hello 程序便正式开始执行了
6. 运行在用户模式，运行过程中，内核不断切换上下文，使运行过程被切分成时间片，与其他进程交替占用执行，实现进程的调度。如果在运行过程中收到信号等，那么就会进入内核模式，运行信号处理程序，之后再返回用户模式。

第二步、存储

1. **fork创建**子进程，为 hello 程序的运行创建上下文，并分配一个与父进程不同的PID。通过 fork 创建的子进程拥有父进程相同的区域结构、页表等的一份副本，同时子进程也可以访问任何父进程已经打开的文件。当 fork 在新进程中返回时，新进程现在的虚拟内存刚好和调用 fork 时存在的虚拟内存相同，当这两个进程中的任一个后来进行写操作时，写时复制机制就会创建新页面，因此，也就为每个进程保持了私有地址空间。
2. **execve() 函数**调用驻留在内核区域的启动加载器代码，在当前进程中加载并运行包含在可执行目标文件 hello 中的程序，用 hello 程序有效地替代了当前程序。加载并运行 hello 需要以下几个步骤：
   1. 删除已存在的用户区域，删除当前进程虚拟地址的用户部分中的已存在的区域结构。
   2. 映射私有区域，为新程序的代码、数据、bss 和栈区域创建新的区域结构，所有这些新的区域都是私有的、写时复制的。代码和数据区域被映射为 hello 文件中的 .text 和 .data 区，bss 区域是请求二进制零的，映射到匿名文件，其大小包含在 hello 中，栈和堆地址也是请求二进制零的，初始长度为零。
   3. 映射共享区域， hello 程序与共享对象 [libc.so](https://link.zhihu.com/?target=http%3A//libc.so/) 链接，[libc.so](https://link.zhihu.com/?target=http%3A//libc.so/) 是动态链接到这个程序中的，然后再映射到用户虚拟地址空间中的共享区域内。
   4. 设置程序计数器（PC），execv() 做的最后一件事情就是设置当前进程上下文的程序计数器，使之指向代码区域的入口点。

第三步、IO管理

所有的 I/O 设备（例如网络、磁盘和终端）都被模型化为文件，而所有的输入和输出都被当作对相应文件的读和写来执行。这使得所有的输入和输出都能以一种统一且一致的方式来执行

1. 随后 write 函数将参数放入寄存器，然后用 int 21h 调用 sys_call 。sys_call 将字符串中的字节从寄存器中通过总线复制到显卡的显存中，显存中存储的是字符的 ASCII 码。
2. 字符显示驱动子程序通过 ASCII 码在字模库中找到点阵信息，并将点阵信息存储到 vram 中。
3. 显示芯片会按照一定的刷新频率逐行读取 vram，并通过信号线向液晶显示器传输每一个点（RGB分量）。
4. 最后，hello 程序的输出：hello 就显示在了屏幕上。、

总结：

- 源程序——hello.c
- 预处理器——hello.i
- 编译器——hello.s
- 汇编器——hello.o
- 链接器——hello
- Shell 创建子进程，真正成为系统中的个体
- 加载器映射虚拟内存，分配空间
- CPU 的逻辑控制流将硬件与操作系统联系起来
- 虚拟地址来进行虚拟内存的管理
- malloc 的高效管理
- 信号与异常约束它的行为，让它总是走在康庄大道之上
- Unix I/O 打开它与程序使用者交流的窗口
- 当 hello 垂垂老矣，运行完最后一行代码，__libc_start_main 将控制转移给内核，Shell 回收子进程，内核删除与它相关的所有数据结构，它在这个世界的所有痕迹至此被抹去。







# 数据库

## Mysql





## Redis
